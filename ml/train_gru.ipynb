{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import json\nimport random\nfrom pathlib import Path\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\n# ------------------------\n# Config\n# ------------------------\nTIERS = {\n    \"0_1k\":    \"sequences_0_1k.json\",\n    \"1k_2k\":   \"sequences_1k_2k.json\",\n    \"2k_7k\":   \"sequences_2k_7k.json\",\n    \"7k_plus\": \"sequences_7k_plus.json\",\n}\n\nSEQ_LEN = 30        # shorter â€” avg sequence lengths are 11-26\nEMBED_DIM = 64\nHIDDEN_DIM = 128\nNUM_LAYERS = 1\nLR = 1e-3\nEPOCHS = 30\nBATCH_SIZE = 32\nVAL_SPLIT = 0.1\n\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Device: {DEVICE}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def load_sequences(path: str):\n    with open(path, \"r\") as f:\n        data = json.load(f)\n    return data[\"sequences\"]\n\n\ndef build_vocab(sequences):\n    tricks = sorted({t for seq in sequences for t in seq})\n    stoi = {t: i for i, t in enumerate(tricks)}\n    itos = {i: t for t, i in stoi.items()}\n    return tricks, stoi, itos\n\n\n# Preview all tiers\nfor tier_name, tier_file in TIERS.items():\n    seqs = load_sequences(tier_file)\n    vocab, _, _ = build_vocab(seqs)\n    lens = [len(s) for s in seqs]\n    print(f\"{tier_name:>8s}: {len(seqs):5d} seqs, {len(vocab):3d} tricks, avg len {sum(lens)/len(lens):.1f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "class NextTrickDataset(Dataset):\n    def __init__(self, sequences, stoi, seq_len):\n        self.samples = []\n\n        for seq in sequences:\n            ids = [stoi[t] for t in seq]\n            if len(ids) < 2:\n                continue\n\n            # Prefix-based samples for short sequences, sliding window for long\n            if len(ids) < seq_len:\n                for j in range(1, len(ids)):\n                    history = ids[:j]\n                    target = ids[j]\n                    padding = [0] * (seq_len - len(history))\n                    self.samples.append((padding + history, target))\n            else:\n                for i in range(len(ids) - seq_len):\n                    self.samples.append((ids[i:i+seq_len], ids[i+seq_len]))\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        x, y = self.samples[idx]\n        return torch.tensor(x, dtype=torch.long), torch.tensor(y, dtype=torch.long)\n\n\nclass TrickGRU(nn.Module):\n    def __init__(self, vocab_size, embed_dim, hidden_dim, num_layers):\n        super().__init__()\n        self.embed = nn.Embedding(vocab_size, embed_dim)\n        self.gru = nn.GRU(embed_dim, hidden_dim, num_layers=num_layers, batch_first=True)\n        self.fc = nn.Linear(hidden_dim, vocab_size)\n\n    def forward(self, x):\n        emb = self.embed(x)\n        out, _ = self.gru(emb)\n        return self.fc(out[:, -1, :])"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def top_k_accuracy(logits, targets, k=3):\n    topk = torch.topk(logits, k, dim=1).indices\n    return (topk == targets.unsqueeze(1)).any(dim=1).float().mean().item()\n\n\ndef train_epoch(model, loader, criterion, optimizer):\n    model.train()\n    total_loss = total_correct = total_top3 = total_top5 = total = 0\n\n    for x, y in loader:\n        x, y = x.to(DEVICE), y.to(DEVICE)\n        logits = model(x)\n        loss = criterion(logits, y)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item() * x.size(0)\n        total_correct += (logits.argmax(dim=1) == y).sum().item()\n        total_top3 += top_k_accuracy(logits, y, k=3) * x.size(0)\n        total_top5 += top_k_accuracy(logits, y, k=5) * x.size(0)\n        total += x.size(0)\n\n    return total_loss/total, total_correct/total, total_top3/total, total_top5/total\n\n\ndef eval_epoch(model, loader, criterion):\n    if loader is None:\n        return None, None, None, None\n    model.eval()\n    total_loss = total_correct = total_top3 = total_top5 = total = 0\n\n    with torch.no_grad():\n        for x, y in loader:\n            x, y = x.to(DEVICE), y.to(DEVICE)\n            logits = model(x)\n            loss = criterion(logits, y)\n\n            total_loss += loss.item() * x.size(0)\n            total_correct += (logits.argmax(dim=1) == y).sum().item()\n            total_top3 += top_k_accuracy(logits, y, k=3) * x.size(0)\n            total_top5 += top_k_accuracy(logits, y, k=5) * x.size(0)\n            total += x.size(0)\n\n    return total_loss/total, total_correct/total, total_top3/total, total_top5/total"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# TRAIN ALL 4 TIER MODELS\n# ============================================================\n\ntrained_models = {}\n\nfor tier_name, tier_file in TIERS.items():\n    print(f\"\\n{'='*60}\")\n    print(f\"  TIER: {tier_name}\")\n    print(f\"{'='*60}\")\n\n    # Load data + build vocab\n    sequences = load_sequences(tier_file)\n    vocab, stoi, itos = build_vocab(sequences)\n    vocab_size = len(vocab)\n    print(f\"Sequences: {len(sequences)}, Vocab: {vocab_size}\")\n\n    # Build dataset\n    dataset = NextTrickDataset(sequences, stoi, SEQ_LEN)\n    print(f\"Training samples: {len(dataset)}\")\n\n    # Train/val split\n    indices = list(range(len(dataset)))\n    random.shuffle(indices)\n    split = int(len(indices) * (1 - VAL_SPLIT))\n\n    train_loader = DataLoader(\n        torch.utils.data.Subset(dataset, indices[:split]),\n        batch_size=BATCH_SIZE, shuffle=True\n    )\n    val_loader = DataLoader(\n        torch.utils.data.Subset(dataset, indices[split:]),\n        batch_size=BATCH_SIZE\n    )\n\n    # Create model\n    model = TrickGRU(vocab_size, EMBED_DIM, HIDDEN_DIM, NUM_LAYERS).to(DEVICE)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n\n    # Track best val loss for early stopping info\n    best_val_loss = float(\"inf\")\n    best_epoch = 0\n\n    for epoch in range(1, EPOCHS + 1):\n        tr_loss, tr_acc, tr_t3, tr_t5 = train_epoch(model, train_loader, criterion, optimizer)\n        va_loss, va_acc, va_t3, va_t5 = eval_epoch(model, val_loader, criterion)\n\n        if va_loss < best_val_loss:\n            best_val_loss = va_loss\n            best_epoch = epoch\n            best_state = {k: v.clone() for k, v in model.state_dict().items()}\n\n        if epoch % 5 == 0 or epoch == 1:\n            print(\n                f\"  Epoch {epoch:02d} | \"\n                f\"train loss {tr_loss:.4f} acc {tr_acc:.3f} t3 {tr_t3:.3f} t5 {tr_t5:.3f} | \"\n                f\"val loss {va_loss:.4f} acc {va_acc:.3f} t3 {va_t3:.3f} t5 {va_t5:.3f}\"\n            )\n\n    # Restore best model\n    model.load_state_dict(best_state)\n    print(f\"  Best val loss {best_val_loss:.4f} at epoch {best_epoch}\")\n\n    # Save checkpoint\n    pt_path = f\"tricks_gru_{tier_name}.pt\"\n    torch.save({\n        \"model_state\": model.state_dict(),\n        \"stoi\": stoi,\n        \"itos\": itos,\n        \"vocab\": vocab,\n        \"seq_len\": SEQ_LEN,\n        \"tier\": tier_name,\n    }, pt_path)\n    print(f\"  Saved {pt_path}\")\n\n    trained_models[tier_name] = {\n        \"model\": model, \"vocab\": vocab, \"stoi\": stoi, \"itos\": itos,\n        \"best_val_loss\": best_val_loss, \"best_epoch\": best_epoch,\n    }"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# EXPORT ALL MODELS: ONNX + JSON\n# ============================================================\n\nfor tier_name, info in trained_models.items():\n    model = info[\"model\"]\n    vocab = info[\"vocab\"]\n    stoi = info[\"stoi\"]\n    itos = info[\"itos\"]\n    model.eval()\n\n    suffix = tier_name\n\n    # ONNX export\n    dummy = torch.randint(0, len(vocab), (1, SEQ_LEN), dtype=torch.long)\n    onnx_path = f\"tricks_gru_{suffix}.onnx\"\n    torch.onnx.export(\n        model, dummy, onnx_path,\n        export_params=True, opset_version=17,\n        input_names=[\"input_ids\"], output_names=[\"logits\"],\n        dynamic_axes={\"input_ids\": {0: \"batch_size\"}, \"logits\": {0: \"batch_size\"}},\n    )\n\n    # JSON exports\n    with open(f\"stoi_{suffix}.json\", \"w\") as f:\n        json.dump(stoi, f, indent=2)\n    with open(f\"itos_{suffix}.json\", \"w\") as f:\n        json.dump({str(k): v for k, v in itos.items()}, f, indent=2)\n    with open(f\"vocab_{suffix}.json\", \"w\") as f:\n        json.dump(vocab, f, indent=2)\n    with open(f\"metadata_{suffix}.json\", \"w\") as f:\n        json.dump({\n            \"vocab_size\": len(vocab),\n            \"seq_len\": SEQ_LEN,\n            \"model_type\": \"GRU\",\n            \"embed_dim\": EMBED_DIM,\n            \"hidden_dim\": HIDDEN_DIM,\n            \"num_layers\": NUM_LAYERS,\n            \"tier\": tier_name,\n        }, f, indent=2)\n\n    print(f\"Exported {tier_name}: {onnx_path}, stoi/itos/vocab/metadata JSONs\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# QUICK TEST: predictions per tier\n# ============================================================\n\ndef predict_topk(model, stoi, itos, trick_history, k=5):\n    ids = [stoi[t] for t in trick_history if t in stoi]\n    if not ids:\n        ids = [0]\n    if len(ids) < SEQ_LEN:\n        ids = [0] * (SEQ_LEN - len(ids)) + ids\n    else:\n        ids = ids[-SEQ_LEN:]\n    x = torch.tensor(ids, dtype=torch.long).unsqueeze(0).to(DEVICE)\n    with torch.no_grad():\n        logits = model(x)\n        probs = F.softmax(logits, dim=-1).squeeze(0)\n    topk = torch.topk(probs, k)\n    return [(itos[idx.item()] if idx.item() in itos else itos.get(str(idx.item()), \"?\"), prob.item())\n            for prob, idx in zip(topk.values, topk.indices)]\n\n\ntest_histories = [[\"S\", \"RS\", \"B\"], [\"B\", \"F\", \"WB\", \"WF\"]]\n\nfor tier_name, info in trained_models.items():\n    print(f\"\\n--- {tier_name} ---\")\n    for hist in test_histories:\n        preds = predict_topk(info[\"model\"], info[\"stoi\"], info[\"itos\"], hist)\n        print(f\"  After {hist}: {preds}\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cs539-venv)",
   "language": "python",
   "name": "cs539-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}